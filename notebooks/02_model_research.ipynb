{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd34a1",
   "metadata": {
    "id": "60cd34a1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd().parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040066c0",
   "metadata": {
    "id": "040066c0"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# DATASET\n",
    "# ==========================================\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, data_path, transforms=None, target_classes=None):\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.target_classes = target_classes\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.target_classes)}\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_name in self.target_classes:\n",
    "            class_path = os.path.join(data_path, class_name)\n",
    "\n",
    "            paths = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG']:\n",
    "                paths.extend(glob.glob(os.path.join(class_path, ext)))\n",
    "\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            self.image_paths.extend(paths)\n",
    "            self.labels.extend([class_idx] * len(paths))\n",
    "\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-rArbbd1S6lr",
   "metadata": {
    "id": "-rArbbd1S6lr"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MODEL\n",
    "# ==========================================\n",
    "\n",
    "# model update weight full\n",
    "def get_transfer_model():\n",
    "  model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "  for layer in model.parameters():\n",
    "    layer.requires_grad =False\n",
    "  model.fc = nn.Sequential(\n",
    "      nn.Dropout(p=0.4),\n",
    "      nn.Linear(in_features=2048, out_features=1024),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Dropout(p=0.4),\n",
    "      nn.Linear(in_features=1024, out_features=8),\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "# freeze weight\n",
    "def unfreeze_layers(model):\n",
    "    for name, child in model.named_children():\n",
    "        if name in ['layer3','layer4']:\n",
    "            for layer in child.modules():\n",
    "                if isinstance(layer, nn.BatchNorm2d):\n",
    "                    layer.eval()\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "                else:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lou5w8UX8O09",
   "metadata": {
    "id": "lou5w8UX8O09"
   },
   "outputs": [],
   "source": [
    "# model = get_transfer_model()\n",
    "# unfreeze_layers(model)\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lu73fpK2-Ugt",
   "metadata": {
    "id": "Lu73fpK2-Ugt"
   },
   "outputs": [],
   "source": [
    "# model = get_transfer_model()\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0QRDuWCv3OLv",
   "metadata": {
    "id": "0QRDuWCv3OLv"
   },
   "outputs": [],
   "source": [
    "# folder\n",
    "TRAIN_DIR = f\"{BASE_DIR}/data/processed\"\n",
    "VALID_DIR = f\"{BASE_DIR}/data/processed_valid\"\n",
    "TEST_DIR = f\"{BASE_DIR}/data/processed_test\"\n",
    "SAVE_PATH = f\"{BASE_DIR}/model\\best_model.pt\"\n",
    "\n",
    "# class\n",
    "TARGET_CLASSES = sorted([\n",
    "    \"AK\",\n",
    "    \"BCC\",\n",
    "    \"BKL\",\n",
    "    \"DF\",\n",
    "    \"MEL\",\n",
    "    \"NV\",\n",
    "    \"SCC\",\n",
    "    \"VASC\"\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 150\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMG_SIZE = 224\n",
    "stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "# dinh nghia transforms cho tap train va tap test\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "\n",
    "# Khoi tao data va dataloader\n",
    "train_dataset = ISICDataset(TRAIN_DIR, transforms=train_transform, target_classes=TARGET_CLASSES)\n",
    "valid_dataset = ISICDataset(VALID_DIR, transforms=test_transform, target_classes=TARGET_CLASSES)\n",
    "test_dataset = ISICDataset(TEST_DIR, transforms=test_transform, target_classes=TARGET_CLASSES)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Tính Class Weights\n",
    "class_counts = Counter(train_dataset.labels)\n",
    "weights = [len(train_dataset) / (len(TARGET_CLASSES) * class_counts[i]) for i in range(len(TARGET_CLASSES))]\n",
    "class_weights_tensor = torch.tensor(weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "# Model\n",
    "model = get_transfer_model()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# loss and optimize\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_JziAVvhtkhq",
   "metadata": {
    "id": "_JziAVvhtkhq"
   },
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter('runs/isic_experiment')\n",
    "\n",
    "\n",
    "# --- 3. Training Loop ---\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(\"===== START =====\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    if epoch == 8:\n",
    "        print(\"\\n ===== UNFREEZE LAYER 4 =====\")\n",
    "        unfreeze_layers(model)\n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': model.layer3.parameters(), 'lr': 1e-5},\n",
    "            {'params': model.layer4.parameters(), 'lr': 1e-5},\n",
    "            {'params': model.fc.parameters(), 'lr': 1e-4}\n",
    "        ], weight_decay=1e-4)\n",
    "    # --- TRAINING PHASE ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_train_preds = []\n",
    "    all_train_targets = []\n",
    "\n",
    "    # Thanh progress bar cho train\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False)\n",
    "\n",
    "    for images, labels in train_bar:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Lưu dự đoán\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_train_preds.extend(preds.cpu().numpy())\n",
    "        all_train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # --- VALIDATION ---\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_val_preds = []\n",
    "    all_val_targets = []\n",
    "\n",
    "    valid_bar = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_bar:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "            all_val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = test_loss / len(valid_loader)\n",
    "\n",
    "    # tinh metrics\n",
    "    precision = precision_score(all_val_targets, all_val_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_val_targets, all_val_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_val_targets, all_val_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # --- Ghi Log TensorBoard ---\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Val', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Metrics/Precision', precision, epoch)\n",
    "    writer.add_scalar('Metrics/Recall', recall, epoch)\n",
    "    writer.add_scalar('Metrics/F1', f1, epoch)\n",
    "\n",
    "    # --- In kết quả ra màn hình ---\n",
    "    print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] Summary:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f}   | Recall:    {recall:.4f}\")\n",
    "\n",
    "    # --- Classification Report (Mỗi 2 epoch) ---\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        print(classification_report(all_val_targets, all_val_preds, target_names=TARGET_CLASSES, zero_division=0))\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "    # --- Lưu Model Tốt Nhất ---\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"  [SAVE] Đã lưu model tốt nhất (Loss giảm xuống {best_loss:.4f}) tại: {SAVE_PATH}\")\n",
    "\n",
    "print(\"\\n XONG\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tqi2MK4x4ouB",
   "metadata": {
    "id": "Tqi2MK4x4ouB"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Tính Cross Entropy Loss bình thường\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "\n",
    "        # Tính pt (xác suất dự đoán đúng)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        # Công thức Focal Loss: (1 - pt)^gamma * log(pt)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nUDQSDq34oq-",
   "metadata": {
    "id": "nUDQSDq34oq-"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tính Class Weights\n",
    "class_counts = Counter(train_dataset.labels)\n",
    "weights = [len(train_dataset) / (len(TARGET_CLASSES) * class_counts[i]) for i in range(len(TARGET_CLASSES))]\n",
    "class_weights_tensor = torch.tensor(weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "# Model\n",
    "checkpoint_path = f\"{BASE_DIR}/model/best_model.pt\"\n",
    "model = get_transfer_model()\n",
    "model = model.to(DEVICE)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "\n",
    "try:\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "except Exception as e:\n",
    "    print(f\"loi {e}\")\n",
    "\n",
    "unfreeze_layers(model)\n",
    "\n",
    "# loss and optimize\n",
    "criterion = FocalLoss(alpha=class_weights_tensor, gamma=2.0)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fE28xHvw_GRR",
   "metadata": {
    "id": "fE28xHvw_GRR"
   },
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter('runs/isic_experiment')\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(\"===== START =====\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- TRAINING PHASE ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_train_preds = []\n",
    "    all_train_targets = []\n",
    "\n",
    "    # Thanh progress bar cho train\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False)\n",
    "\n",
    "    for images, labels in train_bar:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Lưu dự đoán\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_train_preds.extend(preds.cpu().numpy())\n",
    "        all_train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # --- VALIDATION ---\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_val_preds = []\n",
    "    all_val_targets = []\n",
    "\n",
    "    valid_bar = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_bar:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "            all_val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = test_loss / len(valid_loader)\n",
    "\n",
    "    # tinh metrics\n",
    "    precision = precision_score(all_val_targets, all_val_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_val_targets, all_val_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_val_targets, all_val_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # --- Ghi Log TensorBoard ---\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Val', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Metrics/Precision', precision, epoch)\n",
    "    writer.add_scalar('Metrics/Recall', recall, epoch)\n",
    "    writer.add_scalar('Metrics/F1', f1, epoch)\n",
    "\n",
    "    # --- In kết quả ra màn hình ---\n",
    "    print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] Summary:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f}   | Recall:    {recall:.4f}\")\n",
    "\n",
    "    # --- Classification Report (Mỗi 2 epoch) ---\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        print(classification_report(all_val_targets, all_val_preds, target_names=TARGET_CLASSES, zero_division=0))\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "    # --- Lưu Model Tốt Nhất ---\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"  [SAVE] Đã lưu model tốt nhất (Loss giảm xuống {best_loss:.4f}) tại: {SAVE_PATH}\")\n",
    "\n",
    "print(\"\\n XONG\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CuPE9AWf047n",
   "metadata": {
    "id": "CuPE9AWf047n"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/runs/isic_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ixMoGzdfLeCw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixMoGzdfLeCw",
    "outputId": "4fbedcfb-ff2f-4494-e394-9581423ea27f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [Val]:  45%|████▍     | 106/238 [11:11<12:24,  5.64s/it]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "all_test_preds = []\n",
    "all_test_targets = []\n",
    "\n",
    "test_bar = tqdm(test_loader, desc=f\"Epoch [Val]\", leave=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "     for images, labels in test_bar:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_test_preds.extend(preds.cpu().numpy())\n",
    "        all_test_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# tinh metrics\n",
    "precision = precision_score(all_test_targets, all_test_preds, average='weighted', zero_division=0)\n",
    "recall = recall_score(all_test_targets, all_test_preds, average='weighted', zero_division=0)\n",
    "f1 = f1_score(all_test_targets, all_test_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # --- In kết quả ra màn hình ---\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"  Precision:  {precision:.4f}   | Recall:    {recall:.4f}\")\n",
    "\n",
    "    # --- Classification Report (Mỗi 2 epoch) ---\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(all_test_targets, all_test_preds, target_names=TARGET_CLASSES, zero_division=0))\n",
    "print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FmzsiH0W2L95",
   "metadata": {
    "id": "FmzsiH0W2L95"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
